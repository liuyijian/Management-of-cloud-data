# 云数据管理(2) 检索服务 以图搜书 实验报告

*软件63 卢北辰 2016013242*

*软件61 刘译键 2016013239*

## 项目结构

#### 1. 爬虫部分（源码位于src/webspider目录）：

- 基于Scrapy框架实现。
- 使用Scylla作为代理IP池工具，防止被封ip。
- 爬取了京东图书、当当网图书、豆瓣读书的书籍数据。
- 经过数据清洗，总计得到了如下书籍数据：
  - 京东：300945条
  - 豆瓣：40360条
  - 当当：227780条
- 通过MongoDB对爬取的数据进行存储和管理。

#### 2. 前端（源码位于src/frontend目录）：

- 使用Vue框架实现。
- 支持上传图片、指定书名/作者/出版社、显示精准匹配结果、同书名/同作者/同出版社检索结果。

#### 3. 后端 OCR（源码位于src/backend目录）：

- 使用百度OCR库。

#### 4. 后端 检索模块（源码位于src/backend目录）：

- 基于倒排文档、哈希表实现。
- 对书名、作者、出版社关键词，哈希散列后构建倒排文档。
- 搜索时，根据倒排文档，检索得到同书名、同作者、同出版社的结果，取交集得到精准搜索结果，返回给前端。

## 运行说明

#### 前端

- 在控制台进入src/frontend目录
- 执行 npm run serve
- 进入页面后，填写指定关键词，然后点击上传封面图片即启动检索。
- 检索完成后，底部显示精准检索结果，点击各标签显示符合各标签的检索结果（其中不再包含精准结果）。

#### 配置MongoDB

- 连接到 localhost:27017
- 新建数据库 book_data
- 新建集合 book
- 菜单栏选择 Collection/Import Data，导入 data/data.csv

#### 后端

- 在控制台进入src/backend目录
- 执行 python backend.py

#### 运行环境

- Python 3.7.4
- MongoDB 4.2.0
- MongoDB Compass Community 1.19.2

## 遇到的问题及解决方案

- 豆瓣图片爬取问题：

  豆瓣API请求是有限制的，约为每分钟40次，超过了这个次数就要被限制，且同ip的总访问量也有限制。因此，使用同一ip地址只能爬取很少的图书数据，达不到构建数据库的标准。

  解决方案：使用Scylla代理ip池工具，更换ip发起请求，最终爬取了40000条左右的豆瓣图书数据。

- OCR准确性不佳问题：

  OCR能够比较准确地识别大多数书籍的书名和作者，但对艺术字（尤其是很多出版社的字体）识别率很差，导致只能找到同书名/同作者的书，找不到精准结果和同出版社的书。

  解决方案：加入指定字段功能，允许用户填写搜索字段。

- 标题数据量太大，超出MongoDB导出数量限制：

  作者和出版社字段可选值较少，能够正常构建倒排文档。标题数据量太大，超出MongoDB导出数量限制，不支持通过distinct关键词导出。

  解决方案：使用哈希函数将标题映射到较小范围的整数，再对该整数构建倒排文档。

- 豆瓣图片前端无法加载：

  由于前端网页上引用了大量的豆瓣图片，就会出现大量图片无法加载的情况，特别是刷新之后，确定为同一源头发起的请求之后，所有的图片都会被拒绝访问。

  解决方案：使用图片缓存方法，避免使用原本的豆瓣图片链接。

  （参考 https://www.cnblogs.com/yejingping/p/10802290.html ）

## 分工

​	刘译键：爬虫模块、OCR、部分前端

​	卢北辰：后端 检索模块、部分前端、文档、PPT